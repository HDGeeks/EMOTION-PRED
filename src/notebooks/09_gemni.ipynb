{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e33e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Project root: /Users/hd/Desktop/EMOTION-PRED\n",
      "ðŸ“‚ Source root: /Users/hd/Desktop/EMOTION-PRED/src\n",
      "ðŸ“‚ Results root: /Users/hd/Desktop/EMOTION-PRED/src/results\n",
      "ðŸ“‚ Data root: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n",
      "Using dataset directory: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\",\"MAMS-ACSA\",\"raw\",\"data_jsonl\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")\n",
    "# 3 â€” JSONL files\n",
    "TRAIN_JSONL = os.path.join(data_root, \"train.jsonl\")\n",
    "VAL_JSONL   = os.path.join(data_root, \"val.jsonl\")\n",
    "TEST_JSONL  = os.path.join(data_root, \"test.jsonl\")\n",
    "SAMPLE_JSONL = os.path.join(data_root, \"sample.jsonl\")\n",
    "print(\"Using dataset directory:\", data_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1539778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "# import requests\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # -----------------------------\n",
    "# # Load API key\n",
    "# # -----------------------------\n",
    "# load_dotenv()\n",
    "# API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# MODEL = \"models/gemini-2.5-flash\"\n",
    "# URL = f\"https://generativelanguage.googleapis.com/v1beta/{MODEL}:generateContent\"\n",
    "\n",
    "# HEADERS = {\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#     \"X-goog-api-key\": API_KEY\n",
    "# }\n",
    "\n",
    "# # -----------------------------\n",
    "# # Paths\n",
    "# # -----------------------------\n",
    "# IN_PATH = os.path.join(data_root, \"sample_06_12_2025_6pm_annotated.jsonl\")\n",
    "# EMOTION_JSON = os.path.join(data_root, \"emotion.json\")\n",
    "\n",
    "# OUT_DIR = \"output\"\n",
    "# OUT_PATH = os.path.join(OUT_DIR, \"gemini_annotated.jsonl\")\n",
    "# os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Load data + emotion lists\n",
    "# # -----------------------------\n",
    "# data = [json.loads(line) for line in open(IN_PATH, \"r\", encoding=\"utf-8\")]\n",
    "# EMOTIONS = json.load(open(EMOTION_JSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "# # Build lookup table\n",
    "# allowed_lookup = {\n",
    "#     (aspect, polarity): set(EMOTIONS[aspect][polarity])\n",
    "#     for aspect in EMOTIONS\n",
    "#     for polarity in EMOTIONS[aspect]\n",
    "# }\n",
    "\n",
    "# # -----------------------------\n",
    "# # Ask Gemini helper\n",
    "# # -----------------------------\n",
    "# def ask_gemini(prompt):\n",
    "#     payload = {\n",
    "#         \"contents\": [{\"parts\": [{\"text\": prompt}]}]\n",
    "#     }\n",
    "#     r = requests.post(URL, headers=HEADERS, json=payload)\n",
    "#     r.raise_for_status()\n",
    "#     return r.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n",
    "\n",
    "# # -----------------------------\n",
    "# # Get emotion\n",
    "# # -----------------------------\n",
    "# def get_emotion(review, aspect, polarity):\n",
    "#     allowed = allowed_lookup[(aspect, polarity)]\n",
    "\n",
    "#     prompt = f\"\"\"\n",
    "# Choose the emotion toward the given aspect.\n",
    "\n",
    "# Allowed emotions: {list(allowed)}\n",
    "\n",
    "# Rules:\n",
    "# - Respond with EXACTLY ONE WORD from the allowed emotions.\n",
    "# - Do NOT invent new emotions.\n",
    "# - Do NOT output sentiment words.\n",
    "\n",
    "# Review: \"{review}\"\n",
    "# Aspect: \"{aspect}\"\n",
    "# Polarity: \"{polarity}\"\n",
    "\n",
    "# Return ONLY the emotion word.\n",
    "# \"\"\"\n",
    "\n",
    "#     resp = ask_gemini(prompt)\n",
    "#     resp = resp.replace(\".\", \"\").replace(\",\", \"\").title()\n",
    "\n",
    "#     if resp in allowed:\n",
    "#         return resp\n",
    "#     else:\n",
    "#         # fallback: first allowed emotion\n",
    "#         return list(allowed)[0]\n",
    "\n",
    "# # -----------------------------\n",
    "# # Annotate file\n",
    "# # -----------------------------\n",
    "# for row in data:\n",
    "#     text = row[\"input\"]\n",
    "#     for item in row[\"output\"]:\n",
    "#         item[\"emotion\"] = get_emotion(text, item[\"aspect\"], item[\"polarity\"])\n",
    "\n",
    "# # -----------------------------\n",
    "# # Save output\n",
    "# # -----------------------------\n",
    "# with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for row in data:\n",
    "#         f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# print(\"DONE â†’\", OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e7e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE â†’ output/gemini_annotated_aspect_polarity_emotions_200.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -----------------------------\n",
    "# Load API key\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "MODEL = \"models/gemini-2.5-flash\"\n",
    "URL = f\"https://generativelanguage.googleapis.com/v1beta/{MODEL}:generateContent\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"X-goog-api-key\": API_KEY\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "IN_PATH = os.path.join(data_root, \"cleaned.jsonl\")\n",
    "EMOTION_JSON = os.path.join(data_root, \"emotion.json\")\n",
    "\n",
    "OUT_DIR = \"output\"\n",
    "OUT_PATH = os.path.join(OUT_DIR, \"gemini_annotated_aspect_polarity_emotions_200.jsonl\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Load emotion taxonomy\n",
    "# -----------------------------\n",
    "EMOTIONS = json.load(open(EMOTION_JSON, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "ASPECTS = list(EMOTIONS.keys())\n",
    "POLARITIES = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "allowed_lookup = {\n",
    "    (aspect, polarity): EMOTIONS[aspect][polarity]\n",
    "    for aspect in EMOTIONS\n",
    "    for polarity in EMOTIONS[aspect]\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Gemini call\n",
    "# -----------------------------\n",
    "def ask_gemini(prompt):\n",
    "    payload = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
    "    r = requests.post(URL, headers=HEADERS, json=payload)\n",
    "    r.raise_for_status()\n",
    "    return r.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].strip()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# JSON-safe parsing (2-stage repair)\n",
    "# -----------------------------\n",
    "def safe_json_parse(txt):\n",
    "    # Try direct\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try removing code fences\n",
    "    cleaned = txt.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Try removing trailing commas\n",
    "    cleaned = cleaned.replace(\",]\", \"]\").replace(\",}\", \"}\")\n",
    "    try:\n",
    "        return json.loads(cleaned)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Full ABSA extraction with retry\n",
    "# -----------------------------\n",
    "def annotate_full(review):\n",
    "    prompt = f\"\"\"\n",
    "Extract aspects, polarity, and emotion.\n",
    "\n",
    "### Allowed aspects:\n",
    "{ASPECTS}\n",
    "\n",
    "### Allowed polarities:\n",
    "{POLARITIES}\n",
    "\n",
    "### Allowed emotions:\n",
    "{json.dumps(EMOTIONS, indent=2)}\n",
    "\n",
    "### Output format (STRICT):\n",
    "[\n",
    "  {{\"aspect\": \"...\", \"polarity\": \"...\", \"emotion\": \"...\"}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "### Rules:\n",
    "- JSON only.\n",
    "- No explanations.\n",
    "- Emotion must be from the allowed list for that aspect/polarity.\n",
    "- If no aspects â†’ return [].\n",
    "\n",
    "### Review:\n",
    "\"{review}\"\n",
    "\n",
    "Return ONLY a JSON array.\n",
    "\"\"\"\n",
    "\n",
    "    # Retry up to 3 times\n",
    "    for _ in range(3):\n",
    "        response = ask_gemini(prompt)\n",
    "        parsed = safe_json_parse(response)\n",
    "\n",
    "        if isinstance(parsed, list):\n",
    "            break\n",
    "\n",
    "    # Final fallback\n",
    "    if not isinstance(parsed, list):\n",
    "        print(\"JSON ERROR â†’\", response)\n",
    "        return []\n",
    "\n",
    "    # Validate and fix emotions\n",
    "    final = []\n",
    "    for item in parsed:\n",
    "        asp = item.get(\"aspect\")\n",
    "        pol = item.get(\"polarity\")\n",
    "        emo = item.get(\"emotion\", \"\").title()\n",
    "\n",
    "        if (asp, pol) not in allowed_lookup:\n",
    "            continue\n",
    "\n",
    "        allowed = allowed_lookup[(asp, pol)]\n",
    "\n",
    "        if emo not in allowed:\n",
    "            emo = allowed[0]  # fallback\n",
    "\n",
    "        final.append({\n",
    "            \"aspect\": asp,\n",
    "            \"polarity\": pol,\n",
    "            \"emotion\": emo\n",
    "        })\n",
    "\n",
    "    return final\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Load input\n",
    "# -----------------------------\n",
    "raw_data = [\n",
    "    json.loads(line)\n",
    "    for line in open(IN_PATH, \"r\", encoding=\"utf-8\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Annotate all reviews\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "for row in raw_data:\n",
    "    review = row[\"input\"]\n",
    "    triples = annotate_full(review)\n",
    "\n",
    "    results.append({\n",
    "        \"input\": review,\n",
    "        \"output\": triples\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# Save output\n",
    "# -----------------------------\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in results:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"DONE â†’\", OUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
