{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0064c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Project root: /Users/hd/Desktop/EMOTION-PRED\n",
      "ðŸ“‚ Source root: /Users/hd/Desktop/EMOTION-PRED/src\n",
      "ðŸ“‚ Results root: /Users/hd/Desktop/EMOTION-PRED/src/results\n",
      "ðŸ“‚ Data root: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n",
      "Using dataset directory: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\",\"MAMS-ACSA\",\"raw\",\"data_jsonl\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")\n",
    "# 3 â€” JSONL files\n",
    "TRAIN_JSONL = os.path.join(data_root, \"train.jsonl\")\n",
    "VAL_JSONL   = os.path.join(data_root, \"val.jsonl\")\n",
    "TEST_JSONL  = os.path.join(data_root, \"test.jsonl\")\n",
    "SAMPLE_JSONL = os.path.join(data_root, \"sample.jsonl\")\n",
    "print(\"Using dataset directory:\", data_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b72091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "DUMMY BASELINE REPORT\n",
      "========================\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Admiration       0.40      0.17      0.24        12\n",
      "     Annoyance       0.32      0.39      0.35        18\n",
      "      Approval       0.33      0.09      0.14        11\n",
      "     Confusion       0.00      0.00      0.00         4\n",
      "Disappointment       0.14      0.09      0.11        11\n",
      "   Disapproval       0.00      0.00      0.00         4\n",
      "   Frustration       0.00      0.00      0.00         4\n",
      "     Gratitude       0.00      0.00      0.00         2\n",
      "     Impressed       0.00      0.00      0.00         2\n",
      "   Indifferent       0.52      1.00      0.68        44\n",
      "           Joy       0.00      0.00      0.00         4\n",
      "        Relief       0.00      0.00      0.00         1\n",
      "  Satisfaction       0.00      0.00      0.00         4\n",
      "      Surprise       0.00      0.00      0.00         2\n",
      "\n",
      "      accuracy                           0.45       123\n",
      "     macro avg       0.12      0.12      0.11       123\n",
      "  weighted avg       0.31      0.45      0.34       123\n",
      "\n",
      "Macro-F1: 0.1087\n",
      "Micro-F1: 0.4472\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD DATA (triple-level)\n",
    "# -----------------------------\n",
    "PATH = os.path.join(data_root, \"cleaned_300.jsonl\")\n",
    "\n",
    "rows = [json.loads(l) for l in open(PATH, \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "# Convert each triple to ONE training sample\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for row in rows:\n",
    "    review = row[\"input\"]\n",
    "    for t in row[\"output\"]:\n",
    "        aspect = t[\"aspect\"]\n",
    "        polarity = t[\"polarity\"]\n",
    "        emotion = t[\"emotion\"]\n",
    "\n",
    "        # Create a composite text feature\n",
    "        text = f\"{review} [ASPECT={aspect}] [POLARITY={polarity}]\"\n",
    "        \n",
    "        texts.append(text)\n",
    "        labels.append(emotion)\n",
    "\n",
    "# -----------------------------\n",
    "# BUILD MODEL PIPELINE\n",
    "# -----------------------------\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1,2),\n",
    "        stop_words=\"english\"\n",
    "    )),\n",
    "    (\"clf\", LogisticRegression(max_iter=200))\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN / TEST SPLIT\n",
    "# -----------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =  train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TRAIN MODEL\n",
    "# -----------------------------\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# EVALUATE\n",
    "# -----------------------------\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n========================\")\n",
    "print(\"DUMMY BASELINE REPORT\")\n",
    "print(\"========================\\n\")\n",
    "print(classification_report(y_test, pred, zero_division=0))\n",
    "\n",
    "macro = f1_score(y_test, pred, average=\"macro\")\n",
    "micro = f1_score(y_test, pred, average=\"micro\")\n",
    "\n",
    "print(\"Macro-F1:\", round(macro, 4))\n",
    "print(\"Micro-F1:\", round(micro, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
