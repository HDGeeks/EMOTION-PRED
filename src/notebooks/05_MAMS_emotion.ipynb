{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8231c249",
   "metadata": {},
   "source": [
    "Lets use MAMS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\",\"MAMS-ACSA\",\"raw\",\"data_jsonl\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc34d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Must already exist from your unified path resolver\n",
    "# data_root = os.path.join(src_root, \"data\", \"MAMS-ACSA\", \"raw\", \"data_jsonl\")\n",
    "\n",
    "dataset_name = \"MAMS-ACSA\"\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. Paths\n",
    "# ----------------------------------------------------------\n",
    "input_path = os.path.join(data_root, \"train.jsonl\")\n",
    "output_csv = os.path.join(data_root, f\"{dataset_name.lower()}_train_full.csv\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. Skip if already built\n",
    "# ----------------------------------------------------------\n",
    "if os.path.exists(output_csv):\n",
    "    print(f\"Using existing file: {output_csv}\")\n",
    "    print(pd.read_csv(output_csv).head())\n",
    "    raise SystemExit()\n",
    "\n",
    "print(\"Building mams_train_full.csv ...\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. Read JSONL â†’ flatten aspects\n",
    "# ----------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "\n",
    "        row = json.loads(line)\n",
    "        sentence = row[\"input\"]\n",
    "\n",
    "        for item in row[\"output\"]:\n",
    "            records.append({\n",
    "                \"sentence\": sentence,\n",
    "                \"aspect_term\": item.get(\"aspect\", \"\"),\n",
    "                \"polarity\": item.get(\"polarity\", \"\"),\n",
    "                \"emotion\": item.get(\"emotion\", None),\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4. create row_id\n",
    "# ----------------------------------------------------------\n",
    "df[\"row_id\"] = df.index\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5. reorder + save\n",
    "# ----------------------------------------------------------\n",
    "df = df[[\"row_id\", \"sentence\", \"aspect_term\", \"polarity\", \"emotion\"]]\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"âœ” Saved: {output_csv}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add src/ to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from emotion_pipeline_optimized import run_full_emotion_pipeline\n",
    "\n",
    "RESULT_DIR = os.path.join(results_root, f\"emotion_{dataset_name}\")\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "# Check existing CSVs\n",
    "csvs = [f for f in os.listdir(RESULT_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "if not csvs:\n",
    "    t0 = time.time()\n",
    "    run_full_emotion_pipeline(\n",
    "        input_csv=output_csv,        # FIXED\n",
    "        dataset_name=dataset_name,\n",
    "        results_root=results_root,\n",
    "    )\n",
    "    print(\"Pipeline run:\", round(time.time() - t0, 2), \"s\")\n",
    "else:\n",
    "    print(\"Pipeline skipped (existing CSVs detected).\")\n",
    "    print(\"Existing CSVs:\", csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a61e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULT_DIR = os.path.join(results_root, f\"emotion_{dataset_name}\")  # or full dataset\n",
    "csv_files = [f for f in os.listdir(RESULT_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    \"j_hartmann_emotion_english_roberta_large\": \"roberta_large\",\n",
    "    \"nateraw_bert_base_uncased_emotion\": \"bert_base_emotion\",\n",
    "    \"j_hartmann_emotion_english_distilroberta_base\": \"roberta_emotion\",\n",
    "    \"joeddav_distilbert_base_uncased_go_emotions_student\": \"go_emotions\",\n",
    "    \"cardiffnlp_twitter_roberta_base_emotion\": \"tweet_eval\",\n",
    "    \"mrm8488_t5_base_finetuned_emotion\": \"t5_emotion\",\n",
    "    \"SamLowe_roberta_base_go_emotions\": \"go_emotions_roberta\",\n",
    "}\n",
    "\n",
    "merged = None\n",
    "\n",
    "for f in csv_files:\n",
    "    full_path = os.path.join(RESULT_DIR, f)\n",
    "    df = pd.read_csv(full_path)\n",
    "\n",
    "    # get model name\n",
    "    base = f.replace(\"_annotated.csv\", \"\")\n",
    "    colname = MODEL_NAME_MAP.get(base, base)\n",
    "\n",
    "    # keep only row_id + emotion_auto\n",
    "    df = df[[\"row_id\", \"emotion_auto\"]].rename(columns={\n",
    "        \"emotion_auto\": colname\n",
    "    })\n",
    "\n",
    "    # first file initializes\n",
    "    if merged is None:\n",
    "        merged = df\n",
    "    else:\n",
    "        merged = merged.merge(df, on=\"row_id\", how=\"inner\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa93bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) columns to use for voting\n",
    "model_cols = [\n",
    "    \"roberta_large\",\n",
    "    \"bert_base_emotion\",\n",
    "    \"roberta_emotion\",\n",
    "    \"go_emotions\",\n",
    "    \"tweet_eval\",\n",
    "    \"t5_emotion\",\n",
    "    \"go_emotions_roberta\",\n",
    "]\n",
    "\n",
    "# 2) majority vote function\n",
    "def get_majority_emotion(row):\n",
    "    votes = []\n",
    "\n",
    "    for col in model_cols:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            votes.append(row[col])\n",
    "\n",
    "    if len(votes) == 0:\n",
    "        return None\n",
    "\n",
    "    counts = {}\n",
    "    for emo in votes:\n",
    "        counts[emo] = counts.get(emo, 0) + 1\n",
    "\n",
    "    majority_emotion = max(counts.items(), key=lambda x: x[1])[0]\n",
    "    return majority_emotion\n",
    "\n",
    "# 3) apply to all rows\n",
    "merged[\"consensus_emotion\"] = merged.apply(get_majority_emotion, axis=1)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) Add consensus_count = number of model votes\n",
    "# ----------------------------------------------------------\n",
    "def get_consensus_count(row):\n",
    "    emo = row[\"consensus_emotion\"]\n",
    "    if pd.isna(emo):\n",
    "        return 0\n",
    "\n",
    "    return sum(1 for col in model_cols if row[col] == emo)\n",
    "\n",
    "merged[\"consensus_count\"] = merged.apply(get_consensus_count, axis=1)\n",
    "\n",
    "# 5) quick check\n",
    "merged[[\"row_id\"] + model_cols + [\"consensus_emotion\", \"consensus_count\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b62b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_counts = merged[\"consensus_emotion\"].value_counts()\n",
    "print(\"=== Consensus Emotion Distribution ===\")\n",
    "print(consensus_counts)\n",
    "\n",
    "consensus_percent = (merged[\"consensus_emotion\"].value_counts(normalize=True) * 100).round(2)\n",
    "print(\"=== Consensus Emotion Distribution (%) ===\")\n",
    "print(consensus_percent)\n",
    "\n",
    "consensus_stats = pd.DataFrame({\n",
    "    \"count\": merged[\"consensus_emotion\"].value_counts(),\n",
    "    \"percent\": (merged[\"consensus_emotion\"].value_counts(normalize=True) * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"=== Consensus Statistics ===\")\n",
    "consensus_stats\n",
    "\n",
    "strength_counts = merged[\"consensus_count\"].value_counts().sort_index()\n",
    "print(\"=== Consensus Strength (How many models agreed) ===\")\n",
    "print(strength_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f158f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Per-model emotion counts ===\\n\")\n",
    "\n",
    "for col in model_cols:\n",
    "    print(f\"Model: {col}\")\n",
    "    print(merged[col].value_counts())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined table: emotions Ã— models\n",
    "stats = {}\n",
    "\n",
    "for col in model_cols:\n",
    "    stats[col] = merged[col].value_counts()\n",
    "\n",
    "stats_df = pd.DataFrame(stats).fillna(0).astype(int)\n",
    "\n",
    "print(\"=== Emotion frequency per model (rows = emotions, columns = models) ===\")\n",
    "print(stats_df)\n",
    "\n",
    "# Consensus distribution\n",
    "print(\"\\n=== Consensus label distribution ===\")\n",
    "print(merged[\"consensus_emotion\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851fd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "order = merged[\"consensus_emotion\"].value_counts().index\n",
    "\n",
    "sns.barplot(\n",
    "    x=merged[\"consensus_emotion\"].value_counts().index,\n",
    "    y=merged[\"consensus_emotion\"].value_counts().values,\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "\n",
    "plt.title(\"Consensus Emotion Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Emotion\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afacf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "strength = merged[\"consensus_count\"].value_counts().sort_index()\n",
    "\n",
    "sns.barplot(\n",
    "    x=strength.index,\n",
    "    y=strength.values,\n",
    "    palette=\"magma\"\n",
    ")\n",
    "\n",
    "plt.title(\"Consensus Strength (Number of Models Agreeing)\", fontsize=16)\n",
    "plt.xlabel(\"Consensus Count (Votes)\", fontsize=14)\n",
    "plt.ylabel(\"Number of Sentences\", fontsize=14)\n",
    "plt.xticks(strength.index)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7003d1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Make a full copy before remapping\n",
    "# ----------------------------------------------------\n",
    "merged_final = merged.copy()\n",
    "print(\"Original merged shape:\", merged.shape)\n",
    "print(\"New merged_final shape:\", merged_final.shape)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Define final emotion set\n",
    "# ----------------------------------------------------\n",
    "FINAL_EMOTIONS = [\n",
    "    \"neutral\", \"anger\", \"joy\", \"sadness\", \"fear\", \"surprise\", \"disgust\"\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 3. Fine-grained â†’ Basic emotion mapping\n",
    "# ----------------------------------------------------\n",
    "emotion_mapping = {\n",
    "    # Joy cluster\n",
    "    \"joy\": \"joy\",\n",
    "    \"amusement\": \"joy\",\n",
    "    \"excitement\": \"joy\",\n",
    "    \"optimism\": \"joy\",\n",
    "    \"gratitude\": \"joy\",\n",
    "    \"pride\": \"joy\",\n",
    "    \"love\": \"joy\",\n",
    "    \"admiration\": \"joy\",\n",
    "    \"approval\": \"joy\",\n",
    "    \"caring\": \"joy\",\n",
    "    \"desire\": \"joy\",\n",
    "\n",
    "    # Anger cluster\n",
    "    \"anger\": \"anger\",\n",
    "    \"annoyance\": \"anger\",\n",
    "    \"disapproval\": \"anger\",\n",
    "    \"disappointment\": \"anger\",  # Could be sadness; restaurant domain fits anger\n",
    "\n",
    "    # Sadness cluster\n",
    "    \"sadness\": \"sadness\",\n",
    "    \"remorse\": \"sadness\",\n",
    "    \"embarrassment\": \"sadness\",\n",
    "\n",
    "    # Fear cluster\n",
    "    \"fear\": \"fear\",\n",
    "    \"nervousness\": \"fear\",\n",
    "\n",
    "    # Surprise cluster\n",
    "    \"surprise\": \"surprise\",\n",
    "    \"realization\": \"surprise\",\n",
    "    \"confusion\": \"surprise\",\n",
    "\n",
    "    # Disgust cluster\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"repulsion\": \"disgust\",\n",
    "\n",
    "    # Neutral\n",
    "    \"neutral\": \"neutral\",\n",
    "}\n",
    "\n",
    "# Safety fallback: unmapped â†’ neutral\n",
    "def map_final_label(x):\n",
    "    return emotion_mapping.get(x, \"neutral\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 4. Apply mapping\n",
    "# ----------------------------------------------------\n",
    "merged_final[\"emotion_final\"] = merged_final[\"consensus_emotion\"].apply(map_final_label)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. BEFORE â†’ AFTER distributions\n",
    "# ----------------------------------------------------\n",
    "print(\"=== BEFORE (Consensus Emotion Distribution) ===\")\n",
    "print(merged_final[\"consensus_emotion\"].value_counts())\n",
    "\n",
    "print(\"\\n=== AFTER (Final 7-Class Emotion Distribution) ===\")\n",
    "print(merged_final[\"emotion_final\"].value_counts())\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 6. Check if any labels were not mapped\n",
    "# ----------------------------------------------------\n",
    "unmapped = merged_final[\n",
    "    ~merged_final[\"consensus_emotion\"].isin(emotion_mapping.keys())\n",
    "][\"consensus_emotion\"].unique()\n",
    "\n",
    "print(\"\\nUnmapped labels:\", unmapped)\n",
    "\n",
    "# Should output: []\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 7. Visualization of final 7-class distribution\n",
    "# ----------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(\n",
    "    x=merged_final[\"emotion_final\"].value_counts().index,\n",
    "    y=merged_final[\"emotion_final\"].value_counts().values,\n",
    "    palette=\"coolwarm_r\"\n",
    ")\n",
    "\n",
    "plt.title(\"Final 7-Emotion Distribution (After Mapping)\", fontsize=16)\n",
    "plt.xlabel(\"Emotion\", fontsize=14)\n",
    "plt.ylabel(\"Count\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emotion_pipeline_new import annotate\n",
    "df = pd.DataFrame({\n",
    "    \"sentence\": [\"Service was slow but the staff were very friendly.\"],\n",
    "    \"aspect_term\": [[\"service\", \"staff\"]]\n",
    "})\n",
    "\n",
    "preds = annotate(df)\n",
    "for key, value in preds.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1557408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "pipe = pipeline(\"text-classification\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "texts = [\n",
    "    \"[ASPECT] service [SENTENCE] Service was slow but the staff were very friendly.\",\n",
    "    \"[ASPECT] staff [SENTENCE] Service was slow but the staff were very friendly.\"\n",
    "]\n",
    "\n",
    "pipe(texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
