{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8231c249",
   "metadata": {},
   "source": [
    "Lets use MAMS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31daf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset\n",
    "ds = load_dataset(\"NEUDM/mams\")\n",
    "\n",
    "# print dataset info\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds[\"train\"]\n",
    "train_ds = train_ds.to_pandas()\n",
    "\n",
    "\n",
    "# inspect row and column count\n",
    "print(f\"Number of rows: {train_ds.shape[0]}\")\n",
    "print(f\"Number of columns: {train_ds.shape[1]}\")\n",
    "\n",
    "# inspect column names\n",
    "print(\"Column names:\", train_ds.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d30a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "keep_cols = [\"input\", \"output\"]\n",
    "clean_df = train_ds[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc34d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing file: /Users/hd/Desktop/EMOTION-PRED/src/data/mams_train_full.csv\n",
      "   row_id                                           sentence  aspect_term\n",
      "0       0  [\"It might be the best sit down food I've had ...          NaN\n",
      "1       1  ['Hostess was extremely accommodating when we ...          NaN\n",
      "2       2  [\"We were a couple of minutes late for our res...          NaN\n",
      "3       3  ['Though the service might be a little slow, t...          NaN\n",
      "4       4  ['Although we arrived at the restaurant 10 min...          NaN\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------------------\n",
    "# 1. Target CSV location\n",
    "# -----------------------------------------\n",
    "input_csv = os.path.join(data_root, \"mams_train_full.csv\")\n",
    "dataset_name = input_csv.split(\".\")[-2].split(\"/\")[-1] # mams_train_full\n",
    "# -----------------------------------------\n",
    "# 2. If exists â†’ reuse it\n",
    "# -----------------------------------------\n",
    "if os.path.exists(input_csv):\n",
    "    print(f\"Using existing file: {input_csv}\")\n",
    "    df_preview = pd.read_csv(input_csv)\n",
    "    print(df_preview.head())\n",
    "else:\n",
    "    print(\"File not found â†’ building mams_train_full.csv ...\")\n",
    "\n",
    "    # ---- A) Copy dataset ----\n",
    "    df_full = clean_df.copy()\n",
    "\n",
    "    # ---- B) Stable row ID ----\n",
    "    df_full[\"row_id\"] = df_full.index\n",
    "\n",
    "    # ---- C) Clean string format \"['text']\" â†’ \"text\" ----\n",
    "    def clean_list_string(x):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            if isinstance(parsed, list) and len(parsed) > 0:\n",
    "                return parsed[0]\n",
    "            return x\n",
    "        except:\n",
    "            return x\n",
    "\n",
    "    df_full[\"sentence\"] = df_full[\"input\"].apply(clean_list_string)\n",
    "\n",
    "    # ---- D) Empty aspect column (pipeline requirement) ----\n",
    "    df_full[\"aspect_term\"] = \"\"\n",
    "\n",
    "    # ---- E) Save final dataset ----\n",
    "    df_full[[\"row_id\", \"sentence\", \"aspect_term\"]].to_csv(\n",
    "        input_csv, index=False\n",
    "    )\n",
    "\n",
    "    print(f\"âœ” Built and saved: {input_csv}\")\n",
    "    print(df_full[[\"row_id\", \"sentence\", \"aspect_term\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add src/ to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from emotion_pipeline import run_full_emotion_pipeline\n",
    "\n",
    "# run_full_emotion_pipeline(\n",
    "#     input_csv=input_csv,\n",
    "#     dataset_name=\"mams_train_full\",\n",
    "#     results_root=results_root,\n",
    "# )\n",
    "\n",
    "from emotion_pipeline_optimized import run_full_emotion_pipeline\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "run_full_emotion_pipeline(\n",
    "    input_csv=input_csv,\n",
    "    dataset_name=\"mams_train_full\",\n",
    "    results_root=results_root,\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"External total:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46a61e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   row_id go_emotions_roberta roberta_large bert_base_emotion roberta_emotion  \\\n",
      "0       0             neutral       neutral               joy         neutral   \n",
      "1       1             neutral       neutral               joy         neutral   \n",
      "2       2             neutral         anger             anger         neutral   \n",
      "3       3             neutral       neutral               joy         neutral   \n",
      "4       4             neutral         anger             anger         neutral   \n",
      "\n",
      "  t5_emotion  go_emotions tweet_eval  \n",
      "0        joy       caring        joy  \n",
      "1        joy       caring      anger  \n",
      "2      anger  disapproval      anger  \n",
      "3        joy       caring      anger  \n",
      "4      anger    annoyance      anger  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULT_DIR = os.path.join(results_root, f\"emotion_{dataset_name}\")  # or full dataset\n",
    "csv_files = [f for f in os.listdir(RESULT_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    \"j_hartmann_emotion_english_roberta_large\": \"roberta_large\",\n",
    "    \"nateraw_bert_base_uncased_emotion\": \"bert_base_emotion\",\n",
    "    \"j_hartmann_emotion_english_distilroberta_base\": \"roberta_emotion\",\n",
    "    \"joeddav_distilbert_base_uncased_go_emotions_student\": \"go_emotions\",\n",
    "    \"cardiffnlp_twitter_roberta_base_emotion\": \"tweet_eval\",\n",
    "    \"mrm8488_t5_base_finetuned_emotion\": \"t5_emotion\",\n",
    "    \"SamLowe_roberta_base_go_emotions\": \"go_emotions_roberta\",\n",
    "}\n",
    "\n",
    "merged = None\n",
    "\n",
    "for f in csv_files:\n",
    "    full_path = os.path.join(RESULT_DIR, f)\n",
    "    df = pd.read_csv(full_path)\n",
    "\n",
    "    # get model name\n",
    "    base = f.replace(\"_annotated.csv\", \"\")\n",
    "    colname = MODEL_NAME_MAP.get(base, base)\n",
    "\n",
    "    # keep only row_id + emotion_auto\n",
    "    df = df[[\"row_id\", \"emotion_auto\"]].rename(columns={\n",
    "        \"emotion_auto\": colname\n",
    "    })\n",
    "\n",
    "    # first file initializes\n",
    "    if merged is None:\n",
    "        merged = df\n",
    "    else:\n",
    "        merged = merged.merge(df, on=\"row_id\", how=\"inner\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa93bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) columns to use for voting\n",
    "model_cols = [\n",
    "    \"roberta_large\",\n",
    "    \"bert_base_emotion\",\n",
    "    \"roberta_emotion\",\n",
    "    \"go_emotions\",\n",
    "    \"tweet_eval\",\n",
    "    \"t5_emotion\",\n",
    "    \"go_emotions_roberta\",\n",
    "]\n",
    "\n",
    "# 2) majority vote function\n",
    "def get_majority_emotion(row):\n",
    "    votes = []\n",
    "\n",
    "    for col in model_cols:\n",
    "        if col in row and pd.notna(row[col]):\n",
    "            votes.append(row[col])\n",
    "\n",
    "    if len(votes) == 0:\n",
    "        return None\n",
    "\n",
    "    counts = {}\n",
    "    for emo in votes:\n",
    "        if emo not in counts:\n",
    "            counts[emo] = 0\n",
    "        counts[emo] += 1\n",
    "\n",
    "    majority_emotion = max(counts.items(), key=lambda x: x[1])[0]\n",
    "    return majority_emotion\n",
    "\n",
    "# 3) apply to all rows\n",
    "merged[\"consensus_emotion\"] = merged.apply(get_majority_emotion, axis=1)\n",
    "\n",
    "# 4) quick check\n",
    "merged[[\"row_id\"] + model_cols + [\"consensus_emotion\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f158f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Per-model emotion counts ===\\n\")\n",
    "\n",
    "for col in model_cols:\n",
    "    print(f\"Model: {col}\")\n",
    "    print(merged[col].value_counts())\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined table: emotions Ã— models\n",
    "stats = {}\n",
    "\n",
    "for col in model_cols:\n",
    "    stats[col] = merged[col].value_counts()\n",
    "\n",
    "stats_df = pd.DataFrame(stats).fillna(0).astype(int)\n",
    "\n",
    "print(\"=== Emotion frequency per model (rows = emotions, columns = models) ===\")\n",
    "print(stats_df)\n",
    "\n",
    "# Consensus distribution\n",
    "print(\"\\n=== Consensus label distribution ===\")\n",
    "print(merged[\"consensus_emotion\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
