{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8231c249",
   "metadata": {},
   "source": [
    "Lets use MAMS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cfd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31daf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Project root: /Users/hd/Desktop/EMOTION-PRED\n",
      "ðŸ“‚ Source root: /Users/hd/Desktop/EMOTION-PRED/src\n",
      "ðŸ“‚ Results root: /Users/hd/Desktop/EMOTION-PRED/src/results\n",
      "ðŸ“‚ Data root: /Users/hd/Desktop/EMOTION-PRED/src/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b297383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 7446\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset\n",
    "ds = load_dataset(\"NEUDM/mams\")\n",
    "\n",
    "# print dataset info\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9095eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7446\n",
      "Number of columns: 8\n",
      "Column names: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction']\n"
     ]
    }
   ],
   "source": [
    "train_ds = ds[\"train\"]\n",
    "train_ds = train_ds.to_pandas()\n",
    "\n",
    "\n",
    "# inspect row and column count\n",
    "print(f\"Number of rows: {train_ds.shape[0]}\")\n",
    "print(f\"Number of columns: {train_ds.shape[1]}\")\n",
    "\n",
    "# inspect column names\n",
    "print(\"Column names:\", train_ds.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d30a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "keep_cols = [\"input\", \"output\"]\n",
    "clean_df = train_ds[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc34d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Take 50 rows\n",
    "df_head = clean_df[\"input\"].head(50).to_frame()\n",
    "\n",
    "# 1) Convert \"['text']\" â†’ \"text\"\n",
    "def clean_list_string(x):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)   # safely parse list-string\n",
    "        if isinstance(parsed, list) and len(parsed) > 0:\n",
    "            return parsed[0]\n",
    "        return x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "df_head[\"sentence\"] = df_head[\"input\"].apply(clean_list_string)\n",
    "\n",
    "# 2) Add empty aspect column (required by pipeline)\n",
    "df_head[\"aspect_term\"] = \"\"\n",
    "\n",
    "# 3) Save in the correct 2-column format\n",
    "input_csv = os.path.join(data_root, \"temp_50.csv\")\n",
    "df_head[[\"sentence\", \"aspect_term\"]].to_csv(input_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad7c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add src/ to Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85d5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/hd/Desktop/EMOTION-PRED\n",
      "Source root: /Users/hd/Desktop/EMOTION-PRED/src\n",
      "Results root: /Users/hd/Desktop/EMOTION-PRED/src/results\n",
      "\n",
      "Starting full emotion pipeline\n",
      "\n",
      "Saving outputs to: /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50\n",
      "\n",
      "==============================\n",
      "Annotating with: j-hartmann/emotion-english-distilroberta-base\n",
      "==============================\n",
      "  Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/j_hartmann_emotion_english_distilroberta_base_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: j-hartmann/emotion-english-roberta-large\n",
      "==============================\n",
      "  Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/j_hartmann_emotion_english_roberta_large_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: nateraw/bert-base-uncased-emotion\n",
      "==============================\n",
      "  Model type: bert | arch=['BertForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/nateraw_bert_base_uncased_emotion_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: joeddav/distilbert-base-uncased-go-emotions-student\n",
      "==============================\n",
      "  Model type: distilbert | arch=['DistilBertForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/joeddav_distilbert_base_uncased_go_emotions_student_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: cardiffnlp/twitter-roberta-base-emotion\n",
      "==============================\n",
      "  Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/cardiffnlp_twitter_roberta_base_emotion_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: mrm8488/t5-base-finetuned-emotion\n",
      "==============================\n",
      "  Model type: t5 | arch=['T5ForConditionalGeneration']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/mrm8488_t5_base_finetuned_emotion_annotated.csv\n",
      "\n",
      "==============================\n",
      "Annotating with: SamLowe/roberta-base-go_emotions\n",
      "==============================\n",
      "  Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   Saved â†’ /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/SamLowe_roberta_base_go_emotions_annotated.csv\n",
      "\n",
      "Pipeline completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from emotion_pipeline import run_full_emotion_pipeline\n",
    "\n",
    "run_full_emotion_pipeline(\n",
    "    input_csv=input_csv,\n",
    "    dataset_name=\"sample50\",\n",
    "    results_root=results_root,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a61e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   go_emotions_roberta roberta_large bert_base_emotion roberta_emotion  \\\n",
      "0              neutral       neutral               joy         neutral   \n",
      "1              neutral       neutral               joy         neutral   \n",
      "2              neutral         anger             anger         neutral   \n",
      "3              neutral       neutral               joy         neutral   \n",
      "4              neutral         anger             anger         neutral   \n",
      "5              neutral       neutral               joy         neutral   \n",
      "6              neutral      surprise               joy        surprise   \n",
      "7              neutral       neutral               joy         neutral   \n",
      "8              neutral         anger             anger            fear   \n",
      "9              neutral       neutral             anger         neutral   \n",
      "10             neutral       neutral              love         neutral   \n",
      "11             neutral       neutral             anger         neutral   \n",
      "12             neutral       neutral               joy         neutral   \n",
      "13            surprise      surprise          surprise        surprise   \n",
      "14             neutral       neutral             anger         neutral   \n",
      "15             neutral       neutral             anger           anger   \n",
      "16             neutral       neutral               joy             joy   \n",
      "17             neutral      surprise          surprise        surprise   \n",
      "18             neutral       neutral               joy         neutral   \n",
      "19          admiration           joy               joy         neutral   \n",
      "\n",
      "   t5_emotion  go_emotions tweet_eval  \n",
      "0         joy       caring        joy  \n",
      "1         joy       caring      anger  \n",
      "2       anger  disapproval      anger  \n",
      "3         joy       caring      anger  \n",
      "4       anger    annoyance      anger  \n",
      "5         joy       caring        joy  \n",
      "6         joy     surprise        joy  \n",
      "7       anger       caring      anger  \n",
      "8       anger  nervousness      anger  \n",
      "9        love       caring        joy  \n",
      "10       love       caring        joy  \n",
      "11      anger  realization      anger  \n",
      "12      anger       caring        joy  \n",
      "13   surprise     surprise      anger  \n",
      "14      anger       caring      anger  \n",
      "15      anger    confusion      anger  \n",
      "16        joy  realization        joy  \n",
      "17   surprise   admiration        joy  \n",
      "18    sadness       caring        joy  \n",
      "19        joy       caring        joy  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULT_DIR = os.path.join(results_root, \"emotion_sample50\")\n",
    "\n",
    "csv_files = [f for f in os.listdir(RESULT_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    \"j_hartmann_emotion_english_roberta_large\": \"roberta_large\",\n",
    "    \"nateraw_bert_base_uncased_emotion\": \"bert_base_emotion\",\n",
    "    \"j_hartmann_emotion_english_distilroberta_base\": \"roberta_emotion\",\n",
    "    \"joeddav_distilbert_base_uncased_go_emotions_student\": \"go_emotions\",\n",
    "    \"cardiffnlp_twitter_roberta_base_emotion\": \"tweet_eval\",\n",
    "    \"mrm8488_t5_base_finetuned_emotion\": \"t5_emotion\",\n",
    "    \"SamLowe_roberta_base_go_emotions\": \"go_emotions_roberta\",\n",
    "}\n",
    "\n",
    "merged = pd.DataFrame()\n",
    "\n",
    "for f in csv_files:\n",
    "    full_path = os.path.join(RESULT_DIR, f)\n",
    "    df = pd.read_csv(full_path)\n",
    "\n",
    "    base = f.replace(\"_annotated.csv\", \"\")\n",
    "    colname = MODEL_NAME_MAP.get(base, base)   # fallback = raw name if missing\n",
    "\n",
    "    merged[colname] = df[\"emotion_auto\"]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(merged.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
