{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8231c249",
   "metadata": {},
   "source": [
    "Lets use MAMS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cfd70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hd/Desktop/EMOTION-PRED/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.append(\"/Users/hd/Desktop/EMOTION-PRED/src\")\n",
    "\n",
    "from emotion import run_full_emotion_pipeline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b297383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 7446\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction'],\n",
      "        num_rows: 900\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset\n",
    "ds = load_dataset(\"NEUDM/mams\")\n",
    "\n",
    "# print dataset info\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9095eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7446\n",
      "Number of columns: 8\n",
      "Column names: ['task_type', 'dataset', 'input', 'output', 'situation', 'label', 'extra', 'instruction']\n"
     ]
    }
   ],
   "source": [
    "train_ds = ds[\"train\"]\n",
    "train_ds = train_ds.to_pandas()\n",
    "\n",
    "\n",
    "# inspect row and column count\n",
    "print(f\"Number of rows: {train_ds.shape[0]}\")\n",
    "print(f\"Number of columns: {train_ds.shape[1]}\")\n",
    "\n",
    "# inspect column names\n",
    "print(\"Column names:\", train_ds.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d30a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "keep_cols = [\"input\", \"output\"]\n",
    "clean_df = train_ds[keep_cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc34d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[It might be the best sit down food I've had i...</td>\n",
       "      <td>[It might be the best sit down food I've had i...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hostess was extremely accommodating when we a...</td>\n",
       "      <td>[Hostess was extremely accommodating when we a...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[We were a couple of minutes late for our rese...</td>\n",
       "      <td>[We were a couple of minutes late for our rese...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Though the service might be a little slow, th...</td>\n",
       "      <td>[Though the service might be a little slow, th...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Although we arrived at the restaurant 10 min ...</td>\n",
       "      <td>[Although we arrived at the restaurant 10 min ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  [It might be the best sit down food I've had i...   \n",
       "1  [Hostess was extremely accommodating when we a...   \n",
       "2  [We were a couple of minutes late for our rese...   \n",
       "3  [Though the service might be a little slow, th...   \n",
       "4  [Although we arrived at the restaurant 10 min ...   \n",
       "\n",
       "                                            sentence aspect_term  \n",
       "0  [It might be the best sit down food I've had i...              \n",
       "1  [Hostess was extremely accommodating when we a...              \n",
       "2  [We were a couple of minutes late for our rese...              \n",
       "3  [Though the service might be a little slow, th...              \n",
       "4  [Although we arrived at the restaurant 10 min ...              "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Take 50 rows\n",
    "df_head = clean_df[\"input\"].head(50).to_frame()\n",
    "\n",
    "# 1) Convert \"['text']\" ‚Üí \"text\"\n",
    "def clean_list_string(x):\n",
    "    try:\n",
    "        parsed = ast.literal_eval(x)   # safely parse list-string\n",
    "        if isinstance(parsed, list) and len(parsed) > 0:\n",
    "            return parsed[0]\n",
    "        return x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "df_head[\"sentence\"] = df_head[\"input\"].apply(clean_list_string)\n",
    "\n",
    "# 2) Add empty aspect column (required by pipeline)\n",
    "df_head[\"aspect_term\"] = \"\"\n",
    "\n",
    "# 3) Save in the correct 2-column format\n",
    "df_head[[\"sentence\", \"aspect_term\"]].to_csv(\"/Users/hd/Desktop/EMOTION-PRED/src/data/temp_50.csv\", index=False)\n",
    "\n",
    "df_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c85d5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting full emotion pipeline\n",
      "\n",
      "üìÅ Saving outputs to: /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50\n",
      "\n",
      "==============================\n",
      "üîπ Annotating with: j-hartmann/emotion-english-distilroberta-base\n",
      "==============================\n",
      "  üîç Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   ‚úÖ Saved ‚Üí /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/j_hartmann_emotion_english_distilroberta_base_annotated.csv\n",
      "\n",
      "==============================\n",
      "üîπ Annotating with: j-hartmann/emotion-english-roberta-large\n",
      "==============================\n",
      "  üîç Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   ‚úÖ Saved ‚Üí /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/j_hartmann_emotion_english_roberta_large_annotated.csv\n",
      "\n",
      "==============================\n",
      "üîπ Annotating with: nateraw/bert-base-uncased-emotion\n",
      "==============================\n",
      "  üîç Model type: bert | arch=['BertForSequenceClassification']\n",
      "   ‚úÖ Saved ‚Üí /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/nateraw_bert_base_uncased_emotion_annotated.csv\n",
      "\n",
      "==============================\n",
      "üîπ Annotating with: joeddav/distilbert-base-uncased-go-emotions-student\n",
      "==============================\n",
      "  üîç Model type: distilbert | arch=['DistilBertForSequenceClassification']\n",
      "   ‚úÖ Saved ‚Üí /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/joeddav_distilbert_base_uncased_go_emotions_student_annotated.csv\n",
      "\n",
      "==============================\n",
      "üîπ Annotating with: cardiffnlp/twitter-roberta-base-emotion\n",
      "==============================\n",
      "  üîç Model type: roberta | arch=['RobertaForSequenceClassification']\n",
      "   ‚úÖ Saved ‚Üí /Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50/cardiffnlp_twitter_roberta_base_emotion_annotated.csv\n",
      "\n",
      "üéØ Pipeline completed successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from emotion import run_full_emotion_pipeline\n",
    "\n",
    "run_full_emotion_pipeline(\n",
    "    input_csv=\"temp_50.csv\",\n",
    "    dataset_name=\"sample50\",\n",
    "    results_root=\"/Users/hd/Desktop/EMOTION-PRED/src/results/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a61e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   roberta_large bert_base_emotion roberta_emotion  go_emotions tweet_eval\n",
      "0        neutral               joy         neutral       caring        joy\n",
      "1        neutral               joy         neutral       caring      anger\n",
      "2          anger             anger         neutral  disapproval      anger\n",
      "3        neutral               joy         neutral       caring      anger\n",
      "4          anger             anger         neutral    annoyance      anger\n",
      "5        neutral               joy         neutral       caring        joy\n",
      "6       surprise               joy        surprise     surprise        joy\n",
      "7        neutral               joy         neutral       caring      anger\n",
      "8          anger             anger            fear  nervousness      anger\n",
      "9        neutral             anger         neutral       caring        joy\n",
      "10       neutral              love         neutral       caring        joy\n",
      "11       neutral             anger         neutral  realization      anger\n",
      "12       neutral               joy         neutral       caring        joy\n",
      "13      surprise          surprise        surprise     surprise      anger\n",
      "14       neutral             anger         neutral       caring      anger\n",
      "15       neutral             anger           anger    confusion      anger\n",
      "16       neutral               joy             joy  realization        joy\n",
      "17      surprise          surprise        surprise   admiration        joy\n",
      "18       neutral               joy         neutral       caring        joy\n",
      "19           joy               joy         neutral       caring        joy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "RESULT_DIR = \"/Users/hd/Desktop/EMOTION-PRED/src/results/emotion_sample50\"\n",
    "\n",
    "csv_files = [f for f in os.listdir(RESULT_DIR) if f.endswith(\".csv\")]\n",
    "\n",
    "MODEL_NAME_MAP = {\n",
    "    \"j_hartmann_emotion_english_roberta_large\": \"roberta_large\",\n",
    "    \"nateraw_bert_base_uncased_emotion\": \"bert_base_emotion\",\n",
    "    \"j_hartmann_emotion_english_distilroberta_base\": \"roberta_emotion\",\n",
    "    \"joeddav_distilbert_base_uncased_go_emotions_student\": \"go_emotions\",\n",
    "    \"cardiffnlp_twitter_roberta_base_emotion\": \"tweet_eval\"\n",
    "}\n",
    "\n",
    "merged = pd.DataFrame()\n",
    "\n",
    "for f in csv_files:\n",
    "    full_path = os.path.join(RESULT_DIR, f)\n",
    "    df = pd.read_csv(full_path)\n",
    "\n",
    "    base = f.replace(\"_annotated.csv\", \"\")\n",
    "    colname = MODEL_NAME_MAP.get(base, base)   # fallback = raw name if missing\n",
    "\n",
    "    merged[colname] = df[\"emotion_auto\"]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(merged.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
