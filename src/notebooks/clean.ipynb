{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf314e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\",\"MAMS-ACSA\",\"raw\",\"data_jsonl\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")\n",
    "# 3 â€” JSONL files\n",
    "TRAIN_JSONL = os.path.join(data_root, \"train.jsonl\")\n",
    "VAL_JSONL   = os.path.join(data_root, \"val.jsonl\")\n",
    "TEST_JSONL  = os.path.join(data_root, \"test.jsonl\")\n",
    "SAMPLE_JSONL = os.path.join(data_root, \"sample.jsonl\")\n",
    "print(\"Using dataset directory:\", data_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aad354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "INPUT = os.path.join(data_root, \"sample_06_12_2025_6pm_annotated.jsonl\")\n",
    "OUTPUT = os.path.join(data_root, \"cleaned.jsonl\")\n",
    "\n",
    "# Master allowed emotion list\n",
    "ALLOWED = {\n",
    "    \"Admiration\",\"Approval\",\"Relaxation\",\"Excitement\",\"Impressed\",\"Indifferent\",\n",
    "    \"Satisfaction\",\"Joy\",\"Surprise\",\"Gratitude\",\"Annoyance\",\"Disappointment\",\n",
    "    \"Disapproval\",\"Confusion\",\"Fear\",\"Frustration\",\"Relief\"\n",
    "}\n",
    "\n",
    "# Strings that must become Indifferent\n",
    "INVALID = {\n",
    "    None,\"null\",\"None\",\"\", \"mixed emotions\",\"mixed\",\"notdefined\",\n",
    "    \"na\",\"n/a\",\"undefined\",\"indiffernet\",\"indiffrent\"\n",
    "}\n",
    "\n",
    "# Common spelling fixes\n",
    "SPELLING = {\n",
    "    \"appriciation\":\"Appreciation\",\n",
    "    \"impressed\":\"Impressed\",\n",
    "    \"satisified\":\"Satisfaction\",\n",
    "    \"releif\":\"Relief\",\n",
    "    \"satisfied\":\"Satisfaction\",\n",
    "    \"admiration\":\"Admiration\",\n",
    "    \"gratitude\":\"Gratitude\",\n",
    "    \"appreciation\":\"Appreciation\",\n",
    "    \"indifferent\":\"Indifferent\",\n",
    "    \"joy\":\"Joy\",\n",
    "    \"fear\":\"Fear\",\n",
    "    \"confusion\":\"Confusion\",\n",
    "    \"disappointment\":\"Disappointment\",\n",
    "    \"annoyance\":\"Annoyance\",\n",
    "    \"frustration\":\"Frustration\",\n",
    "    \"disgust\":\"Disgust\"  # if needed\n",
    "}\n",
    "\n",
    "def fix_trailing_commas(s):\n",
    "    s = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "def normalize_emotion(e):\n",
    "    if e is None:\n",
    "        return \"Indifferent\"\n",
    "    e = str(e).strip()\n",
    "\n",
    "    if e in INVALID:\n",
    "        return \"Indifferent\"\n",
    "\n",
    "    # lower â†’ capitalized\n",
    "    e_low = e.lower()\n",
    "    # fix misspellings\n",
    "    if e_low in SPELLING:\n",
    "        e = SPELLING[e_low]\n",
    "\n",
    "    # unify capitalization\n",
    "    e = e.capitalize()\n",
    "\n",
    "    # If not allowed â†’ Indifferent\n",
    "    if e not in ALLOWED:\n",
    "        return \"Indifferent\"\n",
    "\n",
    "    return e\n",
    "\n",
    "cleaned = []\n",
    "errors = []\n",
    "\n",
    "with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line_no, line in enumerate(f, start=1):\n",
    "        raw = line.strip()\n",
    "        if not raw:\n",
    "            continue\n",
    "\n",
    "        fixed = fix_trailing_commas(raw)\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(fixed)\n",
    "        except Exception as e:\n",
    "            errors.append((line_no, raw, str(e)))\n",
    "            continue\n",
    "\n",
    "        # Fix emotions in outputs\n",
    "        if \"output\" in obj:\n",
    "            for item in obj[\"output\"]:\n",
    "                item[\"emotion\"] = normalize_emotion(item.get(\"emotion\"))\n",
    "\n",
    "        cleaned.append(obj)\n",
    "\n",
    "# Write clean JSONL\n",
    "with open(OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in cleaned:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"=== DONE CLEANING ===\")\n",
    "print(\"Valid rows:\", len(cleaned))\n",
    "print(\"Invalid rows skipped:\", len(errors))\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors found in rows:\")\n",
    "    for ln, raw, err in errors:\n",
    "        print(f\"Line {ln}: {err}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
