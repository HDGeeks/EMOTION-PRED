{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf314e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Project root: /Users/hd/Desktop/EMOTION-PRED\n",
      "ðŸ“‚ Source root: /Users/hd/Desktop/EMOTION-PRED/src\n",
      "ðŸ“‚ Results root: /Users/hd/Desktop/EMOTION-PRED/src/results\n",
      "ðŸ“‚ Data root: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n",
      "Using dataset directory: /Users/hd/Desktop/EMOTION-PRED/src/data/MAMS-ACSA/raw/data_jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Running as normal Python script inside src/\n",
    "    this_file = os.path.abspath(__file__)\n",
    "    src_root = os.path.dirname(this_file)                        # EMOTION-PRED/src\n",
    "    project_root = os.path.dirname(src_root)                    # EMOTION-PRED/\n",
    "except NameError:\n",
    "    # Running inside Jupyter (likely src/notebooks or src/)\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    # If running inside src/notebooks â†’ go up one level\n",
    "    if cwd.endswith(\"notebooks\"):\n",
    "        src_root = os.path.abspath(os.path.join(cwd, \"..\"))\n",
    "        project_root = os.path.dirname(src_root)\n",
    "    else:\n",
    "        # Running from project root directly\n",
    "        project_root = cwd\n",
    "        src_root = os.path.join(project_root, \"src\")\n",
    "\n",
    "# Final unified paths\n",
    "results_root = os.path.join(src_root, \"results\")\n",
    "data_root = os.path.join(src_root, \"data\",\"MAMS-ACSA\",\"raw\",\"data_jsonl\")\n",
    "print(f\"ðŸ“‚ Project root: {project_root}\"\n",
    "      f\"\\nðŸ“‚ Source root: {src_root}\"\n",
    "      f\"\\nðŸ“‚ Results root: {results_root}\"\n",
    "      f\"\\nðŸ“‚ Data root: {data_root}\")\n",
    "# 3 â€” JSONL files\n",
    "TRAIN_JSONL = os.path.join(data_root, \"train.jsonl\")\n",
    "VAL_JSONL   = os.path.join(data_root, \"val.jsonl\")\n",
    "TEST_JSONL  = os.path.join(data_root, \"test.jsonl\")\n",
    "SAMPLE_JSONL = os.path.join(data_root, \"sample.jsonl\")\n",
    "print(\"Using dataset directory:\", data_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83aad354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DONE CLEANING ===\n",
      "Valid rows: 202\n",
      "Invalid rows skipped: 50\n",
      "\n",
      "Errors found in rows:\n",
      "Line 203: Expecting value: line 1 column 219 (char 218)\n",
      "Line 204: Expecting value: line 1 column 223 (char 222)\n",
      "Line 205: Expecting value: line 1 column 182 (char 181)\n",
      "Line 206: Expecting value: line 1 column 219 (char 218)\n",
      "Line 207: Expecting value: line 1 column 320 (char 319)\n",
      "Line 208: Expecting value: line 1 column 278 (char 277)\n",
      "Line 209: Expecting value: line 1 column 174 (char 173)\n",
      "Line 210: Expecting value: line 1 column 217 (char 216)\n",
      "Line 211: Expecting value: line 1 column 180 (char 179)\n",
      "Line 212: Expecting value: line 1 column 239 (char 238)\n",
      "Line 213: Expecting value: line 1 column 162 (char 161)\n",
      "Line 214: Expecting value: line 1 column 127 (char 126)\n",
      "Line 215: Expecting value: line 1 column 114 (char 113)\n",
      "Line 216: Expecting value: line 1 column 158 (char 157)\n",
      "Line 217: Expecting value: line 1 column 167 (char 166)\n",
      "Line 218: Expecting value: line 1 column 150 (char 149)\n",
      "Line 219: Expecting value: line 1 column 246 (char 245)\n",
      "Line 220: Expecting value: line 1 column 190 (char 189)\n",
      "Line 221: Expecting value: line 1 column 315 (char 314)\n",
      "Line 222: Expecting value: line 1 column 353 (char 352)\n",
      "Line 223: Expecting value: line 1 column 205 (char 204)\n",
      "Line 224: Expecting value: line 1 column 118 (char 117)\n",
      "Line 225: Expecting value: line 1 column 153 (char 152)\n",
      "Line 226: Expecting value: line 1 column 208 (char 207)\n",
      "Line 227: Expecting value: line 1 column 137 (char 136)\n",
      "Line 228: Expecting value: line 1 column 160 (char 159)\n",
      "Line 229: Expecting value: line 1 column 179 (char 178)\n",
      "Line 230: Expecting value: line 1 column 179 (char 178)\n",
      "Line 231: Expecting value: line 1 column 249 (char 248)\n",
      "Line 232: Expecting value: line 1 column 148 (char 147)\n",
      "Line 233: Expecting value: line 1 column 184 (char 183)\n",
      "Line 234: Expecting value: line 1 column 136 (char 135)\n",
      "Line 235: Expecting value: line 1 column 286 (char 285)\n",
      "Line 236: Expecting value: line 1 column 115 (char 114)\n",
      "Line 237: Expecting value: line 1 column 256 (char 255)\n",
      "Line 238: Expecting value: line 1 column 219 (char 218)\n",
      "Line 239: Expecting value: line 1 column 147 (char 146)\n",
      "Line 240: Expecting value: line 1 column 183 (char 182)\n",
      "Line 241: Expecting value: line 1 column 303 (char 302)\n",
      "Line 242: Expecting value: line 1 column 168 (char 167)\n",
      "Line 243: Expecting value: line 1 column 161 (char 160)\n",
      "Line 244: Expecting value: line 1 column 178 (char 177)\n",
      "Line 245: Expecting value: line 1 column 196 (char 195)\n",
      "Line 246: Expecting value: line 1 column 239 (char 238)\n",
      "Line 247: Expecting value: line 1 column 120 (char 119)\n",
      "Line 248: Expecting value: line 1 column 257 (char 256)\n",
      "Line 249: Expecting value: line 1 column 227 (char 226)\n",
      "Line 250: Expecting value: line 1 column 172 (char 171)\n",
      "Line 251: Expecting value: line 1 column 275 (char 274)\n",
      "Line 252: Expecting value: line 1 column 174 (char 173)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "INPUT = os.path.join(data_root, \"sample_06_12_2025_6pm_annotated.jsonl\")\n",
    "OUTPUT = os.path.join(data_root, \"cleaned.jsonl\")\n",
    "\n",
    "# Master allowed emotion list\n",
    "ALLOWED = {\n",
    "    \"Admiration\",\"Approval\",\"Relaxation\",\"Excitement\",\"Impressed\",\"Indifferent\",\n",
    "    \"Satisfaction\",\"Joy\",\"Surprise\",\"Gratitude\",\"Annoyance\",\"Disappointment\",\n",
    "    \"Disapproval\",\"Confusion\",\"Fear\",\"Frustration\",\"Relief\"\n",
    "}\n",
    "\n",
    "# Strings that must become Indifferent\n",
    "INVALID = {\n",
    "    None,\"null\",\"None\",\"\", \"mixed emotions\",\"mixed\",\"notdefined\",\n",
    "    \"na\",\"n/a\",\"undefined\",\"indiffernet\",\"indiffrent\"\n",
    "}\n",
    "\n",
    "# Common spelling fixes\n",
    "SPELLING = {\n",
    "    \"appriciation\":\"Appreciation\",\n",
    "    \"impressed\":\"Impressed\",\n",
    "    \"satisified\":\"Satisfaction\",\n",
    "    \"releif\":\"Relief\",\n",
    "    \"satisfied\":\"Satisfaction\",\n",
    "    \"admiration\":\"Admiration\",\n",
    "    \"gratitude\":\"Gratitude\",\n",
    "    \"appreciation\":\"Appreciation\",\n",
    "    \"indifferent\":\"Indifferent\",\n",
    "    \"joy\":\"Joy\",\n",
    "    \"fear\":\"Fear\",\n",
    "    \"confusion\":\"Confusion\",\n",
    "    \"disappointment\":\"Disappointment\",\n",
    "    \"annoyance\":\"Annoyance\",\n",
    "    \"frustration\":\"Frustration\",\n",
    "    \"disgust\":\"Disgust\"  # if needed\n",
    "}\n",
    "\n",
    "def fix_trailing_commas(s):\n",
    "    s = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "def normalize_emotion(e):\n",
    "    if e is None:\n",
    "        return \"Indifferent\"\n",
    "    e = str(e).strip()\n",
    "\n",
    "    if e in INVALID:\n",
    "        return \"Indifferent\"\n",
    "\n",
    "    # lower â†’ capitalized\n",
    "    e_low = e.lower()\n",
    "    # fix misspellings\n",
    "    if e_low in SPELLING:\n",
    "        e = SPELLING[e_low]\n",
    "\n",
    "    # unify capitalization\n",
    "    e = e.capitalize()\n",
    "\n",
    "    # If not allowed â†’ Indifferent\n",
    "    if e not in ALLOWED:\n",
    "        return \"Indifferent\"\n",
    "\n",
    "    return e\n",
    "\n",
    "cleaned = []\n",
    "errors = []\n",
    "\n",
    "with open(INPUT, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line_no, line in enumerate(f, start=1):\n",
    "        raw = line.strip()\n",
    "        if not raw:\n",
    "            continue\n",
    "\n",
    "        fixed = fix_trailing_commas(raw)\n",
    "\n",
    "        try:\n",
    "            obj = json.loads(fixed)\n",
    "        except Exception as e:\n",
    "            errors.append((line_no, raw, str(e)))\n",
    "            continue\n",
    "\n",
    "        # Fix emotions in outputs\n",
    "        if \"output\" in obj:\n",
    "            for item in obj[\"output\"]:\n",
    "                item[\"emotion\"] = normalize_emotion(item.get(\"emotion\"))\n",
    "\n",
    "        cleaned.append(obj)\n",
    "\n",
    "# Write clean JSONL\n",
    "with open(OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for obj in cleaned:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"=== DONE CLEANING ===\")\n",
    "print(\"Valid rows:\", len(cleaned))\n",
    "print(\"Invalid rows skipped:\", len(errors))\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nErrors found in rows:\")\n",
    "    for ln, raw, err in errors:\n",
    "        print(f\"Line {ln}: {err}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
